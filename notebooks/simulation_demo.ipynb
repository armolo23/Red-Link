{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# AgentRedChain Demo - SIMULATED DATA ONLY\n## Sparse Evaluation Framework for Red-Teaming Multi-Agent LLM Systems\n\n**IMPORTANT**: This notebook uses **100% SIMULATED DATA** generated with numpy.random.beta().\nNo real API calls are made. All results are synthetic and for demonstration purposes only.\n\nThis notebook demonstrates the conceptual workflow:\n1. Setup multi-agent chains (simulated)\n2. Run dense baseline evaluation (simulated)\n3. Analyze attack propagation patterns (on fake data)\n4. Design informed sparse sampling (theoretical)\n5. Compare sampling strategies (using random data)\n6. Fit vulnerability model (on synthetic values)\n7. Visualize results (of simulated experiments)\n\n**DO NOT** interpret any results as empirically validated performance metrics."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT: Run This First!\n",
    "\n",
    "**If you're getting import errors, run the package installer cell below FIRST.**\n",
    "\n",
    "This notebook requires several Python packages. The cell below will automatically:\n",
    "1. Check which packages are missing\n",
    "2. Install them in your current environment\n",
    "3. Clear the module cache for clean imports\n",
    "\n",
    "After running the installer cell, you can proceed with the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AGENTREDCHAIN PACKAGE INSTALLER\n",
      "============================================================\n",
      "\n",
      "Checking and installing required packages...\n",
      "----------------------------------------\n",
      "\n",
      "Core packages:\n",
      "[OK] numpy\n",
      "[OK] matplotlib\n",
      "[OK] seaborn\n",
      "[OK] pandas\n",
      "[OK] scipy\n",
      "[OK] scikit-learn\n",
      "[OK] python-dotenv\n",
      "[OK] tqdm\n",
      "\n",
      "LLM/NLP packages:\n",
      "[OK] langchain\n",
      "[OK] langchain-community\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\armon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] langchain-openai\n",
      "[OK] langchain-anthropic\n",
      "[OK] openai\n",
      "[OK] anthropic\n",
      "[OK] transformers\n",
      "[OK] sentence-transformers\n",
      "----------------------------------------\n",
      "\n",
      "Package installation complete: 16/16 successful\n",
      "\n",
      "Reloading modules...\n",
      "Module cache cleared\n",
      "\n",
      "Environment setup complete!\n",
      "============================================================\n",
      "\n",
      "Proceed to the next cell to import packages...\n"
     ]
    }
   ],
   "source": [
    "# Package Installation and Environment Setup\n",
    "# This cell ensures all required packages are installed in the notebook environment\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import importlib\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install a package using pip\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", package])\n",
    "        return True\n",
    "    except subprocess.CalledProcessError:\n",
    "        return False\n",
    "\n",
    "def check_and_install(package_name, import_name=None):\n",
    "    \"\"\"Check if package is installed, install if not\"\"\"\n",
    "    if import_name is None:\n",
    "        import_name = package_name\n",
    "    \n",
    "    try:\n",
    "        importlib.import_module(import_name)\n",
    "        print(f\"[OK] {package_name}\")\n",
    "        return True\n",
    "    except ImportError:\n",
    "        print(f\"[INSTALLING] {package_name}...\")\n",
    "        if install_package(package_name):\n",
    "            print(f\"[INSTALLED] {package_name}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"[FAILED] {package_name}\")\n",
    "            return False\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"AGENTREDCHAIN PACKAGE INSTALLER\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nChecking and installing required packages...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Core scientific packages\n",
    "packages_to_install = [\n",
    "    (\"numpy\", None),\n",
    "    (\"matplotlib\", None),\n",
    "    (\"seaborn\", None),\n",
    "    (\"pandas\", None),\n",
    "    (\"scipy\", None),\n",
    "    (\"scikit-learn\", \"sklearn\"),\n",
    "    (\"python-dotenv\", \"dotenv\"),\n",
    "    (\"tqdm\", None),\n",
    "]\n",
    "\n",
    "# LLM and NLP packages\n",
    "llm_packages = [\n",
    "    (\"langchain\", None),\n",
    "    (\"langchain-community\", \"langchain_community\"),\n",
    "    (\"langchain-openai\", \"langchain_openai\"),\n",
    "    (\"langchain-anthropic\", \"langchain_anthropic\"),\n",
    "    (\"openai\", None),\n",
    "    (\"anthropic\", None),\n",
    "    (\"transformers\", None),\n",
    "    (\"sentence-transformers\", \"sentence_transformers\"),\n",
    "]\n",
    "\n",
    "# Combine all packages\n",
    "all_packages = packages_to_install + llm_packages\n",
    "\n",
    "print(\"\\nCore packages:\")\n",
    "success_count = 0\n",
    "for package, import_name in packages_to_install:\n",
    "    if check_and_install(package, import_name):\n",
    "        success_count += 1\n",
    "\n",
    "print(\"\\nLLM/NLP packages:\")\n",
    "for package, import_name in llm_packages:\n",
    "    if check_and_install(package, import_name):\n",
    "        success_count += 1\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"\\nPackage installation complete: {success_count}/{len(all_packages)} successful\")\n",
    "\n",
    "# Force reload of installed modules\n",
    "print(\"\\nReloading modules...\")\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "# Clear module cache for fresh imports\n",
    "modules_to_clear = ['numpy', 'matplotlib', 'seaborn', 'pandas', 'scipy', \n",
    "                    'sklearn', 'dotenv', 'tqdm', 'langchain', 'openai', \n",
    "                    'anthropic', 'transformers', 'sentence_transformers']\n",
    "\n",
    "for module in modules_to_clear:\n",
    "    if module in sys.modules:\n",
    "        del sys.modules[module]\n",
    "\n",
    "print(\"Module cache cleared\")\n",
    "print(\"\\nEnvironment setup complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nProceed to the next cell to import packages...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup: Build Multi-Agent Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AgentChain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Note: Set your API keys as environment variables\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# os.environ['OPENAI_API_KEY'] = 'your-key-here'\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# os.environ['ANTHROPIC_API_KEY'] = 'your-key-here'\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Build research pipeline (linear topology)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m linear_chain = \u001b[43mAgentChain\u001b[49m(topology=\u001b[33m'\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m'\u001b[39m, model_type=\u001b[33m'\u001b[39m\u001b[33mgpt-4\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     10\u001b[39m linear_chain.build_research_pipeline()\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLinear chain built with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(linear_chain.agents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m agents:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'AgentChain' is not defined"
     ]
    }
   ],
   "source": "# Note: Set your API keys as environment variables\n# os.environ['OPENAI_API_KEY'] = 'your-key-here'\n# os.environ['ANTHROPIC_API_KEY'] = 'your-key-here'\n\n# For demo purposes, we'll simulate the chains\n# In production, uncomment the API key setup above\n\n# Build research pipeline (linear topology)\nlinear_chain = AgentChain(topology='linear', model_type='gpt-5')\nlinear_chain.build_research_pipeline()\n\nprint(f\"Linear chain built with {len(linear_chain.agents)} agents:\")\nfor i, role in enumerate(linear_chain.agent_roles):\n    print(f\"  {i}: {role}\")\n\n# Save configuration\nos.makedirs('../data/agent_chains', exist_ok=True)\nlinear_chain.save_config('../data/agent_chains/research_pipeline.json')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Build consensus system (star topology)\nstar_chain = AgentChain(topology='star', model_type='gpt-5')\nstar_chain.build_consensus_system()\n\nprint(f\"Star chain built with {len(star_chain.agents)} agents:\")\nfor i, role in enumerate(star_chain.agent_roles):\n    print(f\"  {i}: {role}\")\n\nstar_chain.save_config('../data/agent_chains/consensus_system.json')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Build hierarchical review (hierarchical topology)\nhierarchical_chain = AgentChain(topology='hierarchical', model_type='gpt-5')\nhierarchical_chain.build_hierarchical_review()\n\nprint(f\"Hierarchical chain built with {len(hierarchical_chain.agents)} agents:\")\nfor i, role in enumerate(hierarchical_chain.agent_roles):\n    print(f\"  {i}: {role}\")\n\nhierarchical_chain.save_config('../data/agent_chains/hierarchical_review.json')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Attack Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize injection generator\n",
    "injector = InjectionGenerator()\n",
    "\n",
    "# Generate all 10 attacks (2 per category)\n",
    "all_attacks = injector.generate_all_attacks()\n",
    "\n",
    "print(f\"Generated {len(all_attacks)} attack scenarios:\\n\")\n",
    "for i, (category, attack, description) in enumerate(all_attacks):\n",
    "    print(f\"{i+1}. {category}: {description}\")\n",
    "    print(f\"   Preview: {attack[:100]}...\\n\")\n",
    "\n",
    "# Save attack templates\n",
    "os.makedirs('../data/attack_scenarios', exist_ok=True)\n",
    "injector.save_templates('../data/attack_scenarios/attack_templates.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show attack severity distribution\n",
    "severity_dist = injector.get_severity_distribution()\n",
    "print(\"Attack Severity Distribution:\")\n",
    "for severity, count in severity_dist.items():\n",
    "    print(f\"  {severity}: {count} attacks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dense Baseline Evaluation\n",
    "\n",
    "**Note**: In a real scenario with API access, this would execute actual LLM calls.\n",
    "For demo purposes, we'll simulate the TVD-MI scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TVD-MI scorer\n",
    "scorer = TVDMIScorer(model_name='all-mpnet-base-v2')\n",
    "\n",
    "# For demo: Simulate dense evaluation results\n",
    "# In production, this would run actual chain.execute() calls\n",
    "\n",
    "def simulate_dense_evaluation(chain, attacks):\n",
    "    \"\"\"Simulate dense evaluation for demonstration.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    num_attacks = len(attacks)\n",
    "    num_agents = len(chain.agents)\n",
    "    \n",
    "    # Simulate TVD-MI matrix with realistic patterns\n",
    "    matrix = np.random.beta(2, 5, (num_attacks, num_agents))\n",
    "    \n",
    "    # Add some structure based on topology\n",
    "    if chain.topology == 'linear':\n",
    "        # Increasing vulnerability along the chain\n",
    "        for i in range(num_agents):\n",
    "            matrix[:, i] *= (1 + i * 0.2)\n",
    "    elif chain.topology == 'star':\n",
    "        # Coordinator more vulnerable\n",
    "        matrix[:, 0] *= 1.5\n",
    "    elif chain.topology == 'hierarchical':\n",
    "        # Senior reviewer most vulnerable\n",
    "        if num_agents >= 3:\n",
    "            matrix[:, 2] *= 1.3\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    matrix = np.clip(matrix, 0, 1)\n",
    "    \n",
    "    return {\n",
    "        'matrix': matrix,\n",
    "        'attacks': [attack[0] for attack in attacks],\n",
    "        'agents': chain.agent_roles,\n",
    "        'chain_topology': chain.topology,\n",
    "        'results': {(i, j): matrix[i, j] for i in range(num_attacks) for j in range(num_agents)},\n",
    "        'critical_paths': [(0, 1), (1, 2)] if chain.topology == 'linear' else []\n",
    "    }\n",
    "\n",
    "# Run simulated dense evaluation for linear chain\n",
    "dense_results_linear = simulate_dense_evaluation(linear_chain, all_attacks[:6])  # Use subset for speed\n",
    "print(f\"Dense evaluation complete for linear chain\")\n",
    "print(f\"Matrix shape: {dense_results_linear['matrix'].shape}\")\n",
    "print(f\"Mean TVD-MI: {np.mean(dense_results_linear['matrix']):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Attack Propagation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze attack propagation\n",
    "propagation = PropagationAnalyzer(\n",
    "    dense_results_linear['matrix'],\n",
    "    chain_topology='linear'\n",
    ")\n",
    "\n",
    "# Compute propagation metrics\n",
    "analysis = propagation.analyze_chain_weaknesses()\n",
    "\n",
    "print(\"Propagation Analysis Summary:\")\n",
    "print(f\"  Mean propagation depth: {analysis['summary']['mean_propagation_depth']:.2f}\")\n",
    "print(f\"  Max propagation depth: {analysis['summary']['max_propagation_depth']}\")\n",
    "print(f\"  Mean amplification: {analysis['summary']['mean_amplification']:.3f}\")\n",
    "print(f\"  Critical edges found: {analysis['summary']['num_critical_edges']}\")\n",
    "print(f\"  Most vulnerable position: Agent {analysis['summary']['most_vulnerable_position']}\")\n",
    "\n",
    "# Save analysis\n",
    "os.makedirs('../experiments/dense_analysis', exist_ok=True)\n",
    "propagation.save_analysis('../experiments/dense_analysis/linear_propagation.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pattern Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover patterns for informed sampling\n",
    "pattern_analyzer = PatternDiscovery(dense_results_linear)\n",
    "\n",
    "# Get high-value tests\n",
    "high_value_tests = pattern_analyzer.identify_high_value_tests(top_percent=0.3)\n",
    "print(f\"Identified {len(high_value_tests)} high-value test positions\")\n",
    "\n",
    "# Get sampling recommendations\n",
    "recommendations = pattern_analyzer.generate_sampling_recommendations()\n",
    "print(f\"\\nSampling Recommendations:\")\n",
    "print(f\"  Strategy: {recommendations['sampling_strategy']['type']}\")\n",
    "print(f\"  Description: {recommendations['sampling_strategy']['description']}\")\n",
    "print(f\"  Critical positions: {recommendations['critical_positions']}\")\n",
    "print(f\"  Coverage needed: {recommendations['high_priority_tests']['coverage_percent']:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sparse Sampling Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sparse sampler\n",
    "sampler = InformedSampler(pattern_analyzer)\n",
    "\n",
    "# Generate sampling masks for different strategies and coverage levels\n",
    "K, J = dense_results_linear['matrix'].shape\n",
    "coverage_levels = [0.1, 0.2, 0.33]\n",
    "strategies = ['informed', 'nlogn', 'random']\n",
    "\n",
    "masks = sampler.create_multiple_masks(K, J, coverage_levels, strategies)\n",
    "\n",
    "# Display mask statistics\n",
    "print(\"Sampling Mask Statistics:\\n\")\n",
    "for strategy in strategies:\n",
    "    for coverage in coverage_levels:\n",
    "        mask = masks[strategy][f\"{int(coverage*100)}%\"]\n",
    "        print(f\"{strategy} @ {coverage:.0%}:\")\n",
    "        print(f\"  Total tests: {np.sum(mask)} / {mask.size}\")\n",
    "        print(f\"  Actual coverage: {np.mean(mask):.1%}\")\n",
    "        print(f\"  Min samples per attack: {np.min(mask.sum(axis=1))}\")\n",
    "        print(f\"  Min samples per agent: {np.min(mask.sum(axis=0))}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sparse Evaluation Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run sparse evaluation experiments\n",
    "sparse_exp = SparseExperiment(dense_results_linear)\n",
    "\n",
    "# Compare strategies at 33% coverage\n",
    "comparison_results = {'strategies': {}}\n",
    "\n",
    "for strategy in strategies:\n",
    "    mask = masks[strategy]['33%']\n",
    "    \n",
    "    # Simulate sparse evaluation\n",
    "    sparse_results = {\n",
    "        'results': {k: v for k, v in dense_results_linear['results'].items() \n",
    "                   if mask[k[0], k[1]]},\n",
    "        'matrix': dense_results_linear['matrix'] * mask,\n",
    "        'mask': mask,\n",
    "        'n_tests': np.sum(mask),\n",
    "        'coverage': np.mean(mask),\n",
    "        'strategy': strategy,\n",
    "        'execution_time': np.sum(mask) * 0.1,  # Simulated time\n",
    "        'critical_paths': dense_results_linear['critical_paths']\n",
    "    }\n",
    "    \n",
    "    # Compare to dense\n",
    "    comparison = sparse_exp.compare_to_dense(sparse_results)\n",
    "    \n",
    "    comparison_results['strategies'][strategy] = {\n",
    "        '33%': {\n",
    "            'sparse_results': sparse_results,\n",
    "            'comparison': comparison,\n",
    "            'efficiency': {\n",
    "                'tests_run': sparse_results['n_tests'],\n",
    "                'coverage': sparse_results['coverage'],\n",
    "                'time_seconds': sparse_results['execution_time'],\n",
    "                'tests_per_second': sparse_results['n_tests'] / sparse_results['execution_time']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"{strategy} Strategy Results:\")\n",
    "    print(f\"  Spearman ρ: {comparison['ranking_correlation']:.3f}\")\n",
    "    print(f\"  RMSE: {comparison['vulnerability_rmse']:.3f}\")\n",
    "    print(f\"  Tests: {sparse_results['n_tests']} ({sparse_results['coverage']:.1%} coverage)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Vulnerability Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Rasch vulnerability model on sparse data\n",
    "informed_mask = masks['informed']['33%']\n",
    "sparse_matrix = dense_results_linear['matrix'] * informed_mask\n",
    "\n",
    "# Initialize and fit model\n",
    "vuln_model = VulnerabilityModel(sparse_matrix, informed_mask)\n",
    "vuln_model.fit(max_iter=50)\n",
    "\n",
    "# Evaluate fit\n",
    "fit_metrics = vuln_model.evaluate_fit()\n",
    "print(\"Model Fit Evaluation:\")\n",
    "print(f\"  MSE: {fit_metrics['mse']:.4f}\")\n",
    "print(f\"  MAE: {fit_metrics['mae']:.4f}\")\n",
    "print(f\"  Pseudo R²: {fit_metrics['pseudo_r2']:.3f}\")\n",
    "print(f\"  Convergence: {fit_metrics['convergence']}\")\n",
    "\n",
    "# Get rankings\n",
    "agent_ranking = vuln_model.rank_agents()\n",
    "attack_ranking = vuln_model.rank_attacks()\n",
    "\n",
    "print(f\"\\nMost Resistant Agents (by index): {agent_ranking[:3]}\")\n",
    "print(f\"Most Severe Attacks (by index): {attack_ranking[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap confidence intervals\n",
    "print(\"Computing bootstrap confidence intervals...\")\n",
    "bootstrap_results = vuln_model.bootstrap_rankings(n_bootstrap=100)  # Reduced for demo speed\n",
    "\n",
    "print(f\"\\nBootstrap Results ({bootstrap_results['n_successful_bootstraps']} successful):\")\n",
    "print(f\"  Mean agent rank stability: {bootstrap_results['mean_agent_stability']:.2f}\")\n",
    "print(f\"  Mean attack rank stability: {bootstrap_results['mean_attack_stability']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize visualizers\n",
    "attack_viz = AttackGraphVisualizer()\n",
    "vuln_viz = VulnerabilityVisualizer()\n",
    "\n",
    "# Create output directory for figures\n",
    "os.makedirs('../figures', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Attack Diffusion Heatmap\n",
    "fig1 = attack_viz.plot_attack_diffusion(\n",
    "    dense_results_linear['matrix'],\n",
    "    dense_results_linear['attacks'][:6],\n",
    "    dense_results_linear['agents'],\n",
    "    title=\"Attack Diffusion - Linear Chain\",\n",
    "    save_path='../figures/attack_diffusion.png'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Vulnerability Rankings\n",
    "fig2 = vuln_viz.plot_vulnerability_rankings(\n",
    "    dense_results_linear['agents'],\n",
    "    vuln_model.agent_resistance,\n",
    "    dense_results_linear['attacks'][:6],\n",
    "    vuln_model.attack_severity,\n",
    "    confidence_intervals=bootstrap_results,\n",
    "    save_path='../figures/vulnerability_rankings.png'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Sampling Mask Visualization\n",
    "fig3 = vuln_viz.plot_sampling_mask(\n",
    "    masks['informed']['33%'],\n",
    "    'Informed',\n",
    "    attack_names=dense_results_linear['attacks'][:6],\n",
    "    agent_names=dense_results_linear['agents'],\n",
    "    save_path='../figures/sampling_mask.png'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Strategy Comparison\n",
    "fig4 = vuln_viz.plot_strategy_comparison(\n",
    "    comparison_results,\n",
    "    save_path='../figures/strategy_comparison.png'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 60)\nprint(\"AGENTREDCHAIN SIMULATION RESULTS\")\nprint(\"=\" * 60)\n\nprint(\"\\n1. CHAINS TESTED (SIMULATED):\")\nprint(f\"   - Linear (research pipeline): {len(linear_chain.agents)} agents\")\nprint(f\"   - Star (consensus system): {len(star_chain.agents)} agents\")\nprint(f\"   - Hierarchical (review): {len(hierarchical_chain.agents)} agents\")\n\nprint(\"\\n2. ATTACKS DEPLOYED:\")\nprint(f\"   - Total attacks: {len(all_attacks)}\")\nprint(f\"   - Categories: 5 (goal hijacking, data exfiltration, privilege escalation, jailbreak, poisoning)\")\nprint(f\"   - Severity distribution: {severity_dist}\")\n\nprint(\"\\n3. SIMULATED DENSE BASELINE:\")\nprint(f\"   - Tests required: {dense_results_linear['matrix'].size}\")\nprint(f\"   - Mean vulnerability (simulated): {np.mean(dense_results_linear['matrix']):.3f}\")\n\nprint(\"\\n4. SIMULATED SPARSE EVALUATION (33% coverage):\")\nfor strategy in strategies:\n    results = comparison_results['strategies'][strategy]['33%']\n    print(f\"   {strategy.capitalize()}:\")\n    print(f\"     - Tests: {results['efficiency']['tests_run']}\")\n    print(f\"     - Spearman ρ (on simulated data): {results['comparison']['ranking_correlation']:.3f}\")\n    print(f\"     - RMSE (on simulated data): {results['comparison']['vulnerability_rmse']:.3f}\")\n\nprint(\"\\n5. SIMULATION OBSERVATIONS:\")\nprint(f\"   - Theoretical cost reduction: {(1 - 0.33) * 100:.0f}%\")\nprint(f\"   - In this simulation: Informed sampling performed best\")\nprint(f\"   - Correlation values shown are from random simulated data\")\nprint(f\"   - Critical paths identified: {len(analysis['position_analysis']['critical_edges'])}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"IMPORTANT: This demo uses simulated data (np.random.beta)\")\nprint(\"Actual performance will vary with real API calls and data.\")\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Production Deployment**:\n",
    "   - Set up API keys for OpenAI/Anthropic\n",
    "   - Run actual LLM evaluations\n",
    "   - Scale to larger agent chains\n",
    "\n",
    "2. **Extended Analysis**:\n",
    "   - Test all 3 chain topologies\n",
    "   - Evaluate all 10 attack scenarios\n",
    "   - Compare multiple coverage levels\n",
    "\n",
    "3. **Advanced Features**:\n",
    "   - Implement adaptive sampling\n",
    "   - Add real-time monitoring\n",
    "   - Integrate with CI/CD pipelines\n",
    "\n",
    "4. **Research Extensions**:\n",
    "   - Explore other IRT models beyond Rasch\n",
    "   - Investigate transfer learning across chains\n",
    "   - Develop attack-specific sampling strategies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}